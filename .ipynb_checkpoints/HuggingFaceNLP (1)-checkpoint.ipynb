{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yHFuW-afAEwB",
    "outputId": "71c6ffbe-7316-422c-bf0f-3991838ba96c"
   },
   "outputs": [],
   "source": [
    "%pip install fake-useragent  # Install fake-useragent library\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "url = 'https://www.nytimes.com/section/business'\n",
    "\n",
    "# Create a UserAgent object\n",
    "user_agent = UserAgent()\n",
    "\n",
    "# Set the User-Agent header\n",
    "headers = {'User-Agent': user_agent.chrome}\n",
    "\n",
    "# Send an HTTP GET request to the URL with headers\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Extract headings (h1, h2, h3, etc.)\n",
    "    headings = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
    "\n",
    "    # Extract paragraphs (p)\n",
    "    paragraphs = soup.find_all('p')\n",
    "\n",
    "    # Combine headings and paragraphs into a single string variable\n",
    "    extracted_text = \"\"\n",
    "    for item in headings + paragraphs:\n",
    "        extracted_text += item.get_text() + \"\\n\\n\"  # Add each item's text content to the string variable\n",
    "\n",
    "    # Tokenize the extracted text into sentences\n",
    "    sentences = sent_tokenize(extracted_text)\n",
    "\n",
    "    # Filter out sentences with fewer than 6 words\n",
    "    sentences = [sentence for sentence in sentences if len(sentence.split()) > 5]\n",
    "\n",
    "    # Remove '\\n' characters from sentences\n",
    "    sentences = [sentence.replace('\\n', ' ') for sentence in sentences]\n",
    "\n",
    "    # Print the list of sentences\n",
    "    print(sentences)\n",
    "else:\n",
    "    print('Failed to retrieve the webpage')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4nCeN16DB-EE",
    "outputId": "ecf5199c-ef68-491c-a1eb-c913075429f0"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Define a function to remove extra white spaces from a list of strings\n",
    "def remove_extra_spaces_from_list(sentences):\n",
    "    # Iterate over each string in the list\n",
    "    cleaned_list = []\n",
    "    for text in sentences:\n",
    "        # Use regular expression to replace multiple white spaces with a single white space\n",
    "        cleaned_text = re.sub(r'\\s+', ' ', text)\n",
    "        cleaned_list.append(cleaned_text)\n",
    "    return cleaned_list\n",
    "\n",
    "# Example usage\n",
    "list_with_extra_spaces = [\"This    is     a    sentence   with  extra     spaces.\", \"Another    example   with    extra    spaces.\"]\n",
    "modifiedSentences = remove_extra_spaces_from_list(sentences)\n",
    "print(modifiedSentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W9ut2-YLpf4s",
    "outputId": "a85e10ce-625f-4b0a-b794-10dd836c41d7"
   },
   "outputs": [],
   "source": [
    "!pip install transformer\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"ahmedrachid/FinancialBERT-Sentiment-Analysis\",num_labels=3)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"ahmedrachid/FinancialBERT-Sentiment-Analysis\")\n",
    "\n",
    "nlp = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# sentences = [\"there is a shortage of capital, and we need extra financing\",\n",
    "#              \"growth is strong and we have plenty of liquidity\",\n",
    "#              \"there are doubts about our finances\",\n",
    "#              \"profits are flat\"]\n",
    "results = nlp(sentences)\n",
    "print(modifiedSentences)\n",
    "print(results)\n",
    "print(type(results))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Yzfy48385e2",
    "outputId": "c83b5d57-ca78-4126-a5bd-592bb25ee072"
   },
   "outputs": [],
   "source": [
    "# Iterate over each sentence and its corresponding result\n",
    "for sentence, result in zip(modifiedSentences[:10], results[:10]):\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Sentiment:\", result['label'])\n",
    "    print(\"Score:\", result['score'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "IjLMVJas1Idj",
    "outputId": "cb9ed5e9-ae66-4e3a-f81c-b1d7a712c26a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Output data\n",
    "labels = ['positive', 'neutral', 'negative']\n",
    "label_counts = {'positive': 0, 'neutral': 0, 'negative': 0}\n",
    "label_scores = {'positive': 0, 'neutral': 0, 'negative': 0}\n",
    "\n",
    "# Count the occurrences of each label and calculate total score for each label\n",
    "for result in results:\n",
    "    label = result['label']\n",
    "    label_counts[label] += 1\n",
    "    label_scores[label] += result['score']\n",
    "\n",
    "# Calculate mean score for each label\n",
    "mean_scores = [label_scores[label] / label_counts[label] if label_counts[label] > 0 else 0 for label in labels]\n",
    "\n",
    "# Pie chart\n",
    "sizes = [label_counts[label] for label in labels]\n",
    "colors = ['lightgreen', 'lightblue', 'lightcoral']\n",
    "explode = (0.1, 0, 0)  # explode 1st slice\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "patches, texts, autotexts = plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "\n",
    "# Add mean score value for each label as annotation\n",
    "for i, (label, mean_score) in enumerate(zip(labels, mean_scores)):\n",
    "    texts[i].set_text(f\"{labels[i]} ({mean_score:.2f})\")\n",
    "\n",
    "plt.title('Sentiment Analysis Results')\n",
    "plt.axis('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "c_01gkxQ9z-o",
    "outputId": "e00b3098-406a-4fb1-91b7-2bdb0e4da7a5"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract scores\n",
    "scores = [result['score'] for result in results]\n",
    "\n",
    "# Count the frequency of each score\n",
    "score_counts = {}\n",
    "for score in scores:\n",
    "    if score in score_counts:\n",
    "        score_counts[score] += 1\n",
    "    else:\n",
    "        score_counts[score] = 1\n",
    "\n",
    "# Extract scores and their frequencies\n",
    "sorted_scores = sorted(score_counts.keys())\n",
    "frequencies = [score_counts[score] for score in sorted_scores]\n",
    "\n",
    "# Filter scores and frequencies for scores between 0.99 and 1.0\n",
    "filtered_scores = []\n",
    "filtered_frequencies = []\n",
    "for score, freq in zip(sorted_scores, frequencies):\n",
    "    if 0.97 <= score <= 1.0:\n",
    "        filtered_scores.append(score)\n",
    "        filtered_frequencies.append(freq)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(filtered_scores, filtered_frequencies, marker='o', linestyle='-')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Detailed Representation of Score Values between 0.99 and 1.0')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
